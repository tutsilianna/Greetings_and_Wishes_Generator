{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Xb9sN-A_X0-S"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tutsilianna/Greetings_and_Wishes_Generator/blob/main/Greetings_and_Wishes_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xeq8pw1ms0H"
      },
      "source": [
        "# **Загрузка репозитория с проектом для получения данных**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2fc0R8Qm10p",
        "outputId": "1cdc465e-f931-43ed-9d8f-3d1b390fd5f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Greetings_and_Wishes_Generator'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 43 (delta 15), reused 21 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (43/43), 12.78 MiB | 14.21 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/tutsilianna/Greetings_and_Wishes_Generator.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djpx8z8jm3PH"
      },
      "source": [
        "# **Подключение библиотек и гугл диска**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIc9oTqaMKFG"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from huggingface_hub import notebook_login\n",
        "from IPython.display import clear_output\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import json\n",
        "import math\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "2f8328ba8a6b4559866a44fa58a54bdf",
            "a692a5125f7e4ee3a9f195cb6601af31",
            "473e4f9cc6254233be78bcbc24c67e5a",
            "ff9ab91f753e43a6a28037f83c1896f6",
            "d073c3cf2fb44cc595b8f1cea1e833aa",
            "c545f459e415490c94e293d896fb6c43",
            "369f5bdb3c9c49378dfcaebea09258da",
            "772eb9c6cac84c6084fdba959106f1df",
            "defff822bbb342028788c2ddf2bbad4d",
            "b3bb6db4b250494f906d6f583c275825",
            "9e911e765ce24069a2c06a6c2607d918",
            "65185bb250a84f1f9b5b5521f04e4192",
            "d2341e8728294913bf2e75368674ee20",
            "befbbd73beec4aa89b59ae6a5c146d53",
            "4108920ed9a047d19b255ecfd87171de",
            "77afc947bc934f2f95ff11f11ebfc0ac",
            "50c80bc67244483495641cba519ece40"
          ]
        },
        "id": "zZiz-PNFKHLq",
        "outputId": "18baecf8-2b4a-4232-90c5-2c4cca624796"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f8328ba8a6b4559866a44fa58a54bdf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxm4M6JbQoKB",
        "outputId": "ca0d58e9-16ac-4103-f966-9691f438fa1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb9sN-A_X0-S"
      },
      "source": [
        "# **Чтение и предобработка данных**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прочитаем данные, удалим дубликаты, пустые значения заполним пустыми строками."
      ],
      "metadata": {
        "id": "WXGcI3ga56w5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qxTwnvAKkvn",
        "outputId": "8c7d961b-5b97-4f45-a594-81c46402c0f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 27201 entries, 0 to 95219\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   text         27201 non-null  object\n",
            " 1   likes        27201 non-null  object\n",
            " 2   holiday      27201 non-null  object\n",
            " 3   to           27201 non-null  object\n",
            " 4   description  27201 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/Greetings_and_Wishes_Generator/data/raw/greetings.csv', encoding='utf-8')\n",
        "\n",
        "data.drop_duplicates(inplace=True)\n",
        "data.fillna('', inplace=True)\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Удалим ненужные категории из стобца `holiday` - `Сценарии`, `Конкурсы`, `Розыгрыши`, `Извинения`, `Признания и предложения`."
      ],
      "metadata": {
        "id": "w6zRhDqN6HUP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1tPa-OQ9Ng6",
        "outputId": "28a8cc3c-e77c-48c2-d9ca-cdb47af5c5fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "holiday\n",
              "На день рождения                  9150\n",
              "На праздники                      7356\n",
              "СМС                               3646\n",
              "Тосты                             2125\n",
              "На свадьбу                         938\n",
              "Ежедневные стихи                   899\n",
              "Важные события                     840\n",
              "По профессиям                      836\n",
              "На работу и учебу                  612\n",
              "Поздравления детей и для детей     200\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data = data.loc[(data['holiday'] != \"Сценарии\") & (data['holiday'] != \"Конкурсы\") & (data['holiday'] != \"Розыгрыши\") & (data['holiday'] != \"Извинения\") & (data['holiday'] != \"Признания и предложения\")]\n",
        "\n",
        "data['holiday'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4vmkdb29_NH"
      },
      "outputs": [],
      "source": [
        "\"Всего строк в данных: \" + str(len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данных в столбце  `text` в конце присутствует число, указывающее на количество лайков, оставленных пользователями, уберем его с помощью функции `remove_last_line_if_digits`\n",
        "\n"
      ],
      "metadata": {
        "id": "jreOPqKq9d21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CLQ0bs1bFRk"
      },
      "outputs": [],
      "source": [
        "def remove_last_line_if_digits(text):\n",
        "    lines = text.split('\\n')\n",
        "    last_line = lines[-1]\n",
        "    if last_line.isdigit():\n",
        "        return '\\n'.join(lines[:-1])\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "data['text'] = data['text'].apply(remove_last_line_if_digits)\n",
        "data['text'] = data['text'].str.replace(r\"\\xao\", ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzQdkqNhcvLG"
      },
      "source": [
        "# **Подготовка данных к обучению**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как данных много и обучение проводить тяжело в рамказ Colab, то возьмем только 1000 значений с поздравлениями \"На день рождения\""
      ],
      "metadata": {
        "id": "bFbDjEjY94Ze"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtkdO-9McFy9"
      },
      "outputs": [],
      "source": [
        "data_ = data.copy(deep=True)\n",
        "data_ = data_.loc[data_['holiday'] == 'На день рождения']\n",
        "data_ = data_.loc[data_['to'] != 'Happy Birthday Wishes']\n",
        "data_ = data_[:1000]\n",
        "data_ = shuffle(data_)\n",
        "data_.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Представим данные в виде:\n",
        "\n",
        "#### **`<s>Ключевые слова: [праздник: ... ] [для кого: ... ] [описание: ... ] -> Поздравление: текст поздравления <\\s>`**,\n",
        "\n",
        "разделим на тренировочный и тестовый датасеты и запишем в соответствующие файлы."
      ],
      "metadata": {
        "id": "6qXHn-Y9-K9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_str_ = []\n",
        "for i in range(len(data_)):\n",
        "    item = f'<s>Ключевые слова: [Праздник: {data_.iloc[i][\"holiday\"]}]' + f'[Для кого: {data_.iloc[i][\"to\"]}]' + f'[Описание: {data_.iloc[i][\"description\"]}] ->\\n'\n",
        "    item += 'Поздравление: ' + data_.iloc[i]['text'] + '</s>'\n",
        "    if i < len(data) - 1:\n",
        "        item += '\\n\\n\\n'\n",
        "    data_str_.append(item)\n",
        "\n",
        "\n",
        "X, y = train_test_split(data_str_, test_size=0.2, random_state=42)\n",
        "\n",
        "with open('train.txt', 'w') as file:\n",
        "    for line in X:\n",
        "        file.write(line)\n",
        "\n",
        "with open('test.txt', 'w') as file:\n",
        "    for line in y:\n",
        "        file.write(line)"
      ],
      "metadata": {
        "id": "xqQcKXT0-I6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример получившихся данных"
      ],
      "metadata": {
        "id": "6f9D2DSA-QZ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj6tfkW7WAyA",
        "outputId": "6a61cd28-499c-4182-b18c-84e9c739b768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>Ключевые слова: [Праздник: На день рождения][Для кого: Подруге][Описание: Красивые] ->\n",
            "Поздравление: Подруга понимает с полуслова,\n",
            "Смеётся и грустит вместе с тобой.\n",
            "Совет хороший дать всегда готова,\n",
            "С подругой можно быть просто собой.\n",
            "Подруга выслушает и утешит,\n",
            "С тобой разделит планы и мечты.......\n",
            "Спроси - откуда знаю я всё это?\n",
            "Да потому что у меня есть ТЫ!!!!!!!</s>\n"
          ]
        }
      ],
      "source": [
        "print(data_str_[50].strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IZrThTnae-v"
      },
      "source": [
        "# **Обучение**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Введём переменные `train` и `path`, в которых будут указаны основные данные, необходимые для обучения"
      ],
      "metadata": {
        "id": "QFGcV3Hk-eVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw2nuBJKxMut"
      },
      "outputs": [],
      "source": [
        "train = {\n",
        "    'model_type':         'gpt2',\n",
        "    'train_size':         0.8,\n",
        "    'per_gpu_batch_size': 1,\n",
        "    'gradient_steps':     1,\n",
        "    'num_train_epochs':   1,\n",
        "    'block_size':         150\n",
        "}\n",
        "\n",
        "path = {\n",
        "    'model_load':  '/content/drive/MyDrive/model',\n",
        "    'model_write': '/content/drive/MyDrive/model',\n",
        "    'pretrain':    '/content/ru-gpts/pretrain_transformers.py',\n",
        "    'train':       '/content/train_.txt',\n",
        "    'val':         '/content/test_.txt',\n",
        "    'dataset':     '/content/Greetings_and_Wishes_Generator/data/raw/greetings.csv',\n",
        "    'test_promt':  '/content/promt.txt',\n",
        "    'test_text':   '/content/Greetings_and_Wishes_Generator/data/greetings_text.txt'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим класс `GreetingsGenerator`, с помощью которого можно будет работать с обученной моделью"
      ],
      "metadata": {
        "id": "QClCyAoq_nVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GreetingsGenerator:\n",
        "\n",
        "    # Инициализация гиперпараметров и модели\n",
        "    def __init__(self, path: str) -> None:\n",
        "        self.max_length = 100\n",
        "        self.repetition_penalty = 1.1\n",
        "        self.do_sample = True\n",
        "        self.top_k = 5\n",
        "        self.top_p = 1\n",
        "        self.temperature = 1\n",
        "        self.stop_token = '</s>'\n",
        "        self.tok = GPT2Tokenizer.from_pretrained(path)# , token='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')\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(path).cuda()#, token='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').cuda()\n",
        "        self.use_cuda = True\n",
        "\n",
        "    # Обновление параметров модели, в случае\n",
        "    # отсутсвия соответствующего параметра - ошибка\n",
        "    def update_params(self, **kwargs) -> None:\n",
        "\n",
        "        for key, value in kwargs.items():\n",
        "            params = set(self.__dict__.keys()) - \\\n",
        "                     set([\"model\", \"use_gpu\", \"tok\"])\n",
        "            if key not in params:\n",
        "                raise Exception(f\"Invalid key: {key}\")\n",
        "            self.__dict__[key] = value\n",
        "\n",
        "    #  Генерация поздравления по заданному промту (promt)\n",
        "    def generate(self, promt: str) -> str:\n",
        "\n",
        "        # токенизириуем входной текст\n",
        "        text = f\"<s>{promt}\\n: \"\n",
        "        input = self.tok.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "        # собираем словарь с параметрами для gpt2 модели\n",
        "        # это все поля класса кроме model и token\n",
        "        params = {x: self.__dict__[x] \\\n",
        "            for x in self.__dict__ if x not in [\"model\", \"tok\",'stop_token', 'use_cuda']}\n",
        "\n",
        "        # даем входной ембеддинг и параметры для нашей модельки\n",
        "        if self.use_cuda:\n",
        "            input = input.cuda()\n",
        "        out = self.model.generate(input, **params)\n",
        "        output_text = self.tok.decode(out[0])\n",
        "\n",
        "        try:\n",
        "            # оказывается, что модель выдает поздравление не только по\n",
        "            # заданному промту, но и по другим рандомным промтам.\n",
        "            # поэтому урезаем все что идет после стоп-токена </s>\n",
        "            print(res)\n",
        "            res = str(output_text[:output_text.index(\"<s>\") + 1])[:-1]\n",
        "        except:\n",
        "            # если стоп токена </s> нет, значит текст содержит более\n",
        "            # max_tokens токенов в таком случае оставляем все как есть\n",
        "            res = output_text\n",
        "        # убираем первые две строчки содержащие промт\n",
        "        res = res.split(\"\\n\", 2)[2]\n",
        "        return res\n",
        "\n",
        "    # Сохранение модели в заданную директорию\n",
        "    def save_model(self, path_save: str) -> None:\n",
        "        self.model.save_pretrained(path_save)\n",
        "        self.tok.save_pretrained(path_save)"
      ],
      "metadata": {
        "id": "Gy4fi7c-_0Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объявим переменные для обучения в более явном виде и загрузим репозиторий [ru-gpt](https://github.com/sberbank-ai/ru-gpts) от Сбера, где располагается модель для обучения"
      ],
      "metadata": {
        "id": "S5PVeRLpA02H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI9VXlNBy67Z",
        "outputId": "10c9c290-3ec6-45da-ad62-5ca317327faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ru-gpts'...\n",
            "remote: Enumerating objects: 745, done.\u001b[K\n",
            "remote: Counting objects: 100% (302/302), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 745 (delta 226), reused 210 (delta 190), pack-reused 443\u001b[K\n",
            "Receiving objects: 100% (745/745), 426.54 KiB | 1.65 MiB/s, done.\n",
            "Resolving deltas: 100% (464/464), done.\n"
          ]
        }
      ],
      "source": [
        "train_path          = path['train']\n",
        "val_path            = path['val']\n",
        "pretrain_path       = path['pretrain']\n",
        "model_load_path     = path['model_load']\n",
        "model_write_path    = path['model_write']\n",
        "model_type          = train['model_type']\n",
        "per_gpu_batch_size  = train['per_gpu_batch_size']\n",
        "gradient_steps      = train['gradient_steps']\n",
        "num_train_epochs    = train['num_train_epochs']\n",
        "block_size          = train['block_size']\n",
        "\n",
        "!git clone https://github.com/sberbank-ai/ru-gpts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Не уверена, что нам это нужно, вероятно нужно либо удалить, либо изменить"
      ],
      "metadata": {
        "id": "3aIIEuXDBvTz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQuv1fw8E_zw",
        "outputId": "110a9594-f510-4ce7-b808-008f3c1bf480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing setup.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "! export CUDA_HOME=/usr/local/cuda-10.1\n",
        "! git clone https://github.com/NVIDIA/apex\n",
        "! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex\n",
        "\n",
        "!sh setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перед запуском обучения, необходимо внести следующие изменения в файл `ru-gpts/pretrain_transformers.py`:\n",
        "* `tokenizer.max_len` на `tokenizer.model_max_length`\n",
        "* `AutoModelWithLMHead` на `AutoModelForCausalLM`\n",
        "\n",
        "В процессе обучения модель сохраняется в директорию из переменной `model_write_path`"
      ],
      "metadata": {
        "id": "sYYSanmmB0s4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddp1MCZuFHzd",
        "outputId": "6152edbc-9ca9-4a4e-f61f-dd1ac3c3a31e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-20 18:47:27.002808: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-20 18:47:27.002878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-20 18:47:27.004695: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-20 18:47:28.093811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/20/2024 18:47:29 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "config.json: 100% 622/622 [00:00<00:00, 2.76MB/s]\n",
            "tokenizer_config.json: 100% 1.25k/1.25k [00:00<00:00, 6.78MB/s]\n",
            "vocab.json: 100% 1.71M/1.71M [00:00<00:00, 3.70MB/s]\n",
            "merges.txt: 100% 1.27M/1.27M [00:00<00:00, 5.42MB/s]\n",
            "special_tokens_map.json: 100% 574/574 [00:00<00:00, 3.09MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1699: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n",
            "pytorch_model.bin: 100% 3.14G/3.14G [00:07<00:00, 415MB/s]\n",
            "05/20/2024 18:47:49 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/content/train_.txt', output_dir='model_write_path', model_type='gpt2', eval_data_file='/content/test_.txt', line_by_line=False, should_continue=False, model_name_or_path='sberbank-ai/rugpt3large_based_on_gpt2', mlm=False, mlm_probability=0.15, config_name=None, tokenizer_name=None, cache_dir=None, block_size=150, do_train=True, do_eval=True, evaluate_during_training=False, per_gpu_train_batch_size=1, per_gpu_eval_batch_size=4, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=500, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'))\n",
            "05/20/2024 18:47:49 - INFO - __main__ -   Creating features from dataset file at /content\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (111539 > 2048). Running this sequence through the model will result in indexing errors\n",
            "05/20/2024 18:47:49 - INFO - __main__ -   Saving features into cached file /content/gpt2_cached_lm_150_train_.txt\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "05/20/2024 18:47:50 - INFO - __main__ -   ***** Running training *****\n",
            "05/20/2024 18:47:50 - INFO - __main__ -     Num examples = 743\n",
            "05/20/2024 18:47:50 - INFO - __main__ -     Num Epochs = 1\n",
            "05/20/2024 18:47:50 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
            "05/20/2024 18:47:50 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "05/20/2024 18:47:50 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "05/20/2024 18:47:50 - INFO - __main__ -     Total optimization steps = 743\n",
            "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/743 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/743 [00:01<15:34,  1.26s/it]\u001b[A\n",
            "Iteration:   0% 2/743 [00:01<07:22,  1.67it/s]\u001b[A\n",
            "Iteration:   0% 3/743 [00:01<04:44,  2.60it/s]\u001b[A\n",
            "Iteration:   1% 4/743 [00:01<03:29,  3.53it/s]\u001b[A\n",
            "Iteration:   1% 5/743 [00:01<02:47,  4.41it/s]\u001b[A\n",
            "Iteration:   1% 6/743 [00:01<02:22,  5.18it/s]\u001b[A\n",
            "Iteration:   1% 7/743 [00:02<02:06,  5.81it/s]\u001b[A\n",
            "Iteration:   1% 8/743 [00:02<01:56,  6.32it/s]\u001b[A\n",
            "Iteration:   1% 9/743 [00:02<01:49,  6.73it/s]\u001b[A\n",
            "Iteration:   1% 10/743 [00:02<01:44,  7.04it/s]\u001b[A\n",
            "Iteration:   1% 11/743 [00:02<01:40,  7.27it/s]\u001b[A\n",
            "Iteration:   2% 12/743 [00:02<01:38,  7.43it/s]\u001b[A\n",
            "Iteration:   2% 13/743 [00:02<01:36,  7.55it/s]\u001b[A\n",
            "Iteration:   2% 14/743 [00:02<01:35,  7.63it/s]\u001b[A\n",
            "Iteration:   2% 15/743 [00:03<01:34,  7.68it/s]\u001b[A\n",
            "Iteration:   2% 16/743 [00:03<01:34,  7.73it/s]\u001b[A\n",
            "Iteration:   2% 17/743 [00:03<01:33,  7.75it/s]\u001b[A\n",
            "Iteration:   2% 18/743 [00:03<01:33,  7.78it/s]\u001b[A\n",
            "Iteration:   3% 19/743 [00:03<01:32,  7.80it/s]\u001b[A\n",
            "Iteration:   3% 20/743 [00:03<01:32,  7.82it/s]\u001b[A\n",
            "Iteration:   3% 21/743 [00:03<01:32,  7.82it/s]\u001b[A\n",
            "Iteration:   3% 22/743 [00:03<01:32,  7.84it/s]\u001b[A\n",
            "Iteration:   3% 23/743 [00:04<01:31,  7.84it/s]\u001b[A\n",
            "Iteration:   3% 24/743 [00:04<01:31,  7.85it/s]\u001b[A\n",
            "Iteration:   3% 25/743 [00:04<01:31,  7.86it/s]\u001b[A\n",
            "Iteration:   3% 26/743 [00:04<01:31,  7.83it/s]\u001b[A\n",
            "Iteration:   4% 27/743 [00:04<01:31,  7.83it/s]\u001b[A\n",
            "Iteration:   4% 28/743 [00:04<01:31,  7.83it/s]\u001b[A\n",
            "Iteration:   4% 29/743 [00:04<01:31,  7.82it/s]\u001b[A\n",
            "Iteration:   4% 30/743 [00:04<01:31,  7.83it/s]\u001b[A\n",
            "Iteration:   4% 31/743 [00:05<01:30,  7.85it/s]\u001b[A\n",
            "Iteration:   4% 32/743 [00:05<01:30,  7.84it/s]\u001b[A\n",
            "Iteration:   4% 33/743 [00:05<01:30,  7.85it/s]\u001b[A\n",
            "Iteration:   5% 34/743 [00:05<01:30,  7.81it/s]\u001b[A\n",
            "Iteration:   5% 35/743 [00:05<01:30,  7.79it/s]\u001b[A\n",
            "Iteration:   5% 36/743 [00:05<01:30,  7.77it/s]\u001b[A\n",
            "Iteration:   5% 37/743 [00:05<01:30,  7.79it/s]\u001b[A\n",
            "Iteration:   5% 38/743 [00:05<01:30,  7.81it/s]\u001b[A\n",
            "Iteration:   5% 39/743 [00:06<01:30,  7.77it/s]\u001b[A\n",
            "Iteration:   5% 40/743 [00:06<01:30,  7.78it/s]\u001b[A\n",
            "Iteration:   6% 41/743 [00:06<01:30,  7.77it/s]\u001b[A\n",
            "Iteration:   6% 42/743 [00:06<01:30,  7.78it/s]\u001b[A\n",
            "Iteration:   6% 43/743 [00:06<01:29,  7.80it/s]\u001b[A\n",
            "Iteration:   6% 44/743 [00:06<01:29,  7.80it/s]\u001b[A\n",
            "Iteration:   6% 45/743 [00:06<01:29,  7.81it/s]\u001b[A\n",
            "Iteration:   6% 46/743 [00:07<01:29,  7.79it/s]\u001b[A\n",
            "Iteration:   6% 47/743 [00:07<01:29,  7.78it/s]\u001b[A\n",
            "Iteration:   6% 48/743 [00:07<01:29,  7.80it/s]\u001b[A\n",
            "Iteration:   7% 49/743 [00:07<01:28,  7.80it/s]\u001b[A\n",
            "Iteration:   7% 50/743 [00:07<01:28,  7.81it/s]\u001b[A\n",
            "Iteration:   7% 51/743 [00:07<01:28,  7.81it/s]\u001b[A\n",
            "Iteration:   7% 52/743 [00:07<01:28,  7.81it/s]\u001b[A\n",
            "Iteration:   7% 53/743 [00:07<01:28,  7.83it/s]\u001b[A\n",
            "Iteration:   7% 54/743 [00:08<01:28,  7.81it/s]\u001b[A\n",
            "Iteration:   7% 55/743 [00:08<01:27,  7.83it/s]\u001b[A\n",
            "Iteration:   8% 56/743 [00:08<01:27,  7.83it/s]\u001b[A\n",
            "Iteration:   8% 57/743 [00:08<01:27,  7.83it/s]\u001b[A\n",
            "Iteration:   8% 58/743 [00:08<01:27,  7.84it/s]\u001b[A\n",
            "Iteration:   8% 59/743 [00:08<01:27,  7.85it/s]\u001b[A\n",
            "Iteration:   8% 60/743 [00:08<01:27,  7.84it/s]\u001b[A\n",
            "Iteration:   8% 61/743 [00:08<01:27,  7.84it/s]\u001b[A\n",
            "Iteration:   8% 62/743 [00:09<01:26,  7.84it/s]\u001b[A\n",
            "Iteration:   8% 63/743 [00:09<01:26,  7.85it/s]\u001b[A\n",
            "Iteration:   9% 64/743 [00:09<01:26,  7.82it/s]\u001b[A\n",
            "Iteration:   9% 65/743 [00:09<01:26,  7.80it/s]\u001b[A\n",
            "Iteration:   9% 66/743 [00:09<01:26,  7.80it/s]\u001b[A\n",
            "Iteration:   9% 67/743 [00:09<01:26,  7.79it/s]\u001b[A\n",
            "Iteration:   9% 68/743 [00:09<01:26,  7.79it/s]\u001b[A\n",
            "Iteration:   9% 69/743 [00:09<01:26,  7.82it/s]\u001b[A\n",
            "Iteration:   9% 70/743 [00:10<01:26,  7.82it/s]\u001b[A\n",
            "Iteration:  10% 71/743 [00:10<01:26,  7.81it/s]\u001b[A\n",
            "Iteration:  10% 72/743 [00:10<01:25,  7.81it/s]\u001b[A\n",
            "Iteration:  10% 73/743 [00:10<01:25,  7.81it/s]\u001b[A\n",
            "Iteration:  10% 74/743 [00:10<01:25,  7.80it/s]\u001b[A\n",
            "Iteration:  10% 75/743 [00:10<01:25,  7.80it/s]\u001b[A\n",
            "Iteration:  10% 76/743 [00:10<01:25,  7.79it/s]\u001b[A\n",
            "Iteration:  10% 77/743 [00:10<01:25,  7.80it/s]\u001b[A\n",
            "Iteration:  10% 78/743 [00:11<01:25,  7.81it/s]\u001b[A\n",
            "Iteration:  11% 79/743 [00:11<01:24,  7.81it/s]\u001b[A\n",
            "Iteration:  11% 80/743 [00:11<01:24,  7.81it/s]\u001b[A\n",
            "Iteration:  11% 81/743 [00:11<01:24,  7.80it/s]\u001b[A\n",
            "Iteration:  11% 82/743 [00:11<01:24,  7.81it/s]\u001b[A\n",
            "Iteration:  11% 83/743 [00:11<01:24,  7.80it/s]\u001b[A\n",
            "Iteration:  11% 84/743 [00:11<01:24,  7.80it/s]\u001b[A\n",
            "Iteration:  11% 85/743 [00:12<01:24,  7.77it/s]\u001b[A\n",
            "Iteration:  12% 86/743 [00:12<01:24,  7.79it/s]\u001b[A\n",
            "Iteration:  12% 87/743 [00:12<01:24,  7.79it/s]\u001b[A\n",
            "Iteration:  12% 88/743 [00:12<01:23,  7.80it/s]\u001b[A\n",
            "Iteration:  12% 89/743 [00:12<01:23,  7.80it/s]\u001b[A\n",
            "Iteration:  12% 90/743 [00:12<01:23,  7.81it/s]\u001b[A\n",
            "Iteration:  12% 91/743 [00:12<01:23,  7.81it/s]\u001b[A\n",
            "Iteration:  12% 92/743 [00:12<01:23,  7.81it/s]\u001b[A\n",
            "Iteration:  13% 93/743 [00:13<01:23,  7.82it/s]\u001b[A\n",
            "Iteration:  13% 94/743 [00:13<01:23,  7.80it/s]\u001b[A\n",
            "Iteration:  13% 95/743 [00:13<01:23,  7.80it/s]\u001b[A\n",
            "Iteration:  13% 96/743 [00:13<01:23,  7.79it/s]\u001b[A\n",
            "Iteration:  13% 97/743 [00:13<01:22,  7.81it/s]\u001b[A\n",
            "Iteration:  13% 98/743 [00:13<01:22,  7.81it/s]\u001b[A\n",
            "Iteration:  13% 99/743 [00:13<01:22,  7.82it/s]\u001b[A\n",
            "Iteration:  13% 100/743 [00:13<01:22,  7.82it/s]\u001b[A\n",
            "Iteration:  14% 101/743 [00:14<01:22,  7.82it/s]\u001b[A\n",
            "Iteration:  14% 102/743 [00:14<01:21,  7.82it/s]\u001b[A\n",
            "Iteration:  14% 103/743 [00:14<01:21,  7.83it/s]\u001b[A\n",
            "Iteration:  14% 104/743 [00:14<01:21,  7.84it/s]\u001b[A\n",
            "Iteration:  14% 105/743 [00:14<01:21,  7.84it/s]\u001b[A\n",
            "Iteration:  14% 106/743 [00:14<01:21,  7.84it/s]\u001b[A\n",
            "Iteration:  14% 107/743 [00:14<01:21,  7.83it/s]\u001b[A\n",
            "Iteration:  15% 108/743 [00:14<01:21,  7.84it/s]\u001b[A\n",
            "Iteration:  15% 109/743 [00:15<01:20,  7.83it/s]\u001b[A\n",
            "Iteration:  15% 110/743 [00:15<01:20,  7.83it/s]\u001b[A\n",
            "Iteration:  15% 111/743 [00:15<01:20,  7.83it/s]\u001b[A\n",
            "Iteration:  15% 112/743 [00:15<01:20,  7.83it/s]\u001b[A\n",
            "Iteration:  15% 113/743 [00:15<01:20,  7.83it/s]\u001b[A\n",
            "Iteration:  15% 114/743 [00:15<01:20,  7.83it/s]\u001b[A\n",
            "Iteration:  15% 115/743 [00:15<01:20,  7.83it/s]\u001b[A\n",
            "Iteration:  16% 116/743 [00:15<01:20,  7.82it/s]\u001b[A\n",
            "Iteration:  16% 117/743 [00:16<01:20,  7.81it/s]\u001b[A\n",
            "Iteration:  16% 118/743 [00:16<01:19,  7.82it/s]\u001b[A\n",
            "Iteration:  16% 119/743 [00:16<01:19,  7.84it/s]\u001b[A\n",
            "Iteration:  16% 120/743 [00:16<01:19,  7.80it/s]\u001b[A\n",
            "Iteration:  16% 121/743 [00:16<01:19,  7.81it/s]\u001b[A\n",
            "Iteration:  16% 122/743 [00:16<01:19,  7.82it/s]\u001b[A\n",
            "Iteration:  17% 123/743 [00:16<01:19,  7.83it/s]\u001b[A\n",
            "Iteration:  17% 124/743 [00:17<01:19,  7.81it/s]\u001b[A\n",
            "Iteration:  17% 125/743 [00:17<01:18,  7.82it/s]\u001b[A\n",
            "Iteration:  17% 126/743 [00:17<01:19,  7.81it/s]\u001b[A\n",
            "Iteration:  17% 127/743 [00:17<01:18,  7.81it/s]\u001b[A\n",
            "Iteration:  17% 128/743 [00:17<01:18,  7.82it/s]\u001b[A\n",
            "Iteration:  17% 129/743 [00:17<01:18,  7.83it/s]\u001b[A\n",
            "Iteration:  17% 130/743 [00:17<01:18,  7.84it/s]\u001b[A\n",
            "Iteration:  18% 131/743 [00:17<01:18,  7.83it/s]\u001b[A\n",
            "Iteration:  18% 132/743 [00:18<01:18,  7.82it/s]\u001b[A\n",
            "Iteration:  18% 133/743 [00:18<01:17,  7.83it/s]\u001b[A\n",
            "Iteration:  18% 134/743 [00:18<01:18,  7.79it/s]\u001b[A\n",
            "Iteration:  18% 135/743 [00:18<01:18,  7.79it/s]\u001b[A\n",
            "Iteration:  18% 136/743 [00:18<01:17,  7.80it/s]\u001b[A\n",
            "Iteration:  18% 137/743 [00:18<01:17,  7.82it/s]\u001b[A\n",
            "Iteration:  19% 138/743 [00:18<01:17,  7.84it/s]\u001b[A\n",
            "Iteration:  19% 139/743 [00:18<01:17,  7.83it/s]\u001b[A\n",
            "Iteration:  19% 140/743 [00:19<01:16,  7.84it/s]\u001b[A\n",
            "Iteration:  19% 141/743 [00:19<01:16,  7.84it/s]\u001b[A\n",
            "Iteration:  19% 142/743 [00:19<01:16,  7.84it/s]\u001b[A\n",
            "Iteration:  19% 143/743 [00:19<01:16,  7.84it/s]\u001b[A\n",
            "Iteration:  19% 144/743 [00:19<01:16,  7.84it/s]\u001b[A\n",
            "Iteration:  20% 145/743 [00:19<01:16,  7.84it/s]\u001b[A\n",
            "Iteration:  20% 146/743 [00:19<01:16,  7.84it/s]\u001b[A\n",
            "Iteration:  20% 147/743 [00:19<01:15,  7.84it/s]\u001b[A\n",
            "Iteration:  20% 148/743 [00:20<01:15,  7.84it/s]\u001b[A\n",
            "Iteration:  20% 149/743 [00:20<01:15,  7.83it/s]\u001b[A\n",
            "Iteration:  20% 150/743 [00:20<01:16,  7.77it/s]\u001b[A\n",
            "Iteration:  20% 151/743 [00:20<01:16,  7.79it/s]\u001b[A\n",
            "Iteration:  20% 152/743 [00:20<01:15,  7.81it/s]\u001b[A\n",
            "Iteration:  21% 153/743 [00:20<01:15,  7.85it/s]\u001b[A\n",
            "Iteration:  21% 154/743 [00:20<01:15,  7.83it/s]\u001b[A\n",
            "Iteration:  21% 155/743 [00:20<01:15,  7.84it/s]\u001b[A\n",
            "Iteration:  21% 156/743 [00:21<01:14,  7.85it/s]\u001b[A\n",
            "Iteration:  21% 157/743 [00:21<01:14,  7.84it/s]\u001b[A\n",
            "Iteration:  21% 158/743 [00:21<01:14,  7.81it/s]\u001b[A\n",
            "Iteration:  21% 159/743 [00:21<01:14,  7.82it/s]\u001b[A\n",
            "Iteration:  22% 160/743 [00:21<01:14,  7.82it/s]\u001b[A\n",
            "Iteration:  22% 161/743 [00:21<01:14,  7.80it/s]\u001b[A\n",
            "Iteration:  22% 162/743 [00:21<01:14,  7.81it/s]\u001b[A\n",
            "Iteration:  22% 163/743 [00:21<01:14,  7.81it/s]\u001b[A\n",
            "Iteration:  22% 164/743 [00:22<01:14,  7.81it/s]\u001b[A\n",
            "Iteration:  22% 165/743 [00:22<01:13,  7.82it/s]\u001b[A\n",
            "Iteration:  22% 166/743 [00:22<01:13,  7.82it/s]\u001b[A\n",
            "Iteration:  22% 167/743 [00:22<01:13,  7.80it/s]\u001b[A\n",
            "Iteration:  23% 168/743 [00:22<01:13,  7.80it/s]\u001b[A\n",
            "Iteration:  23% 169/743 [00:22<01:13,  7.81it/s]\u001b[A\n",
            "Iteration:  23% 170/743 [00:22<01:13,  7.82it/s]\u001b[A\n",
            "Iteration:  23% 171/743 [00:23<01:13,  7.82it/s]\u001b[A\n",
            "Iteration:  23% 172/743 [00:23<01:13,  7.81it/s]\u001b[A\n",
            "Iteration:  23% 173/743 [00:23<01:13,  7.78it/s]\u001b[A\n",
            "Iteration:  23% 174/743 [00:23<01:12,  7.81it/s]\u001b[A\n",
            "Iteration:  24% 175/743 [00:23<01:12,  7.83it/s]\u001b[A\n",
            "Iteration:  24% 176/743 [00:23<01:12,  7.84it/s]\u001b[A\n",
            "Iteration:  24% 177/743 [00:23<01:12,  7.85it/s]\u001b[A\n",
            "Iteration:  24% 178/743 [00:23<01:11,  7.85it/s]\u001b[A\n",
            "Iteration:  24% 179/743 [00:24<01:11,  7.84it/s]\u001b[A\n",
            "Iteration:  24% 180/743 [00:24<01:11,  7.83it/s]\u001b[A\n",
            "Iteration:  24% 181/743 [00:24<01:11,  7.83it/s]\u001b[A\n",
            "Iteration:  24% 182/743 [00:24<01:11,  7.84it/s]\u001b[A\n",
            "Iteration:  25% 183/743 [00:24<01:11,  7.85it/s]\u001b[A\n",
            "Iteration:  25% 184/743 [00:24<01:11,  7.85it/s]\u001b[A\n",
            "Iteration:  25% 185/743 [00:24<01:11,  7.86it/s]\u001b[A\n",
            "Iteration:  25% 186/743 [00:24<01:10,  7.87it/s]\u001b[A\n",
            "Iteration:  25% 187/743 [00:25<01:10,  7.88it/s]\u001b[A\n",
            "Iteration:  25% 188/743 [00:25<01:10,  7.87it/s]\u001b[A\n",
            "Iteration:  25% 189/743 [00:25<01:10,  7.86it/s]\u001b[A\n",
            "Iteration:  26% 190/743 [00:25<01:10,  7.83it/s]\u001b[A\n",
            "Iteration:  26% 191/743 [00:25<01:10,  7.83it/s]\u001b[A\n",
            "Iteration:  26% 192/743 [00:25<01:10,  7.84it/s]\u001b[A\n",
            "Iteration:  26% 193/743 [00:25<01:10,  7.85it/s]\u001b[A\n",
            "Iteration:  26% 194/743 [00:25<01:09,  7.85it/s]\u001b[A\n",
            "Iteration:  26% 195/743 [00:26<01:09,  7.84it/s]\u001b[A\n",
            "Iteration:  26% 196/743 [00:26<01:09,  7.83it/s]\u001b[A\n",
            "Iteration:  27% 197/743 [00:26<01:10,  7.78it/s]\u001b[A\n",
            "Iteration:  27% 198/743 [00:26<01:09,  7.80it/s]\u001b[A\n",
            "Iteration:  27% 199/743 [00:26<01:09,  7.79it/s]\u001b[A\n",
            "Iteration:  27% 200/743 [00:26<01:09,  7.81it/s]\u001b[A\n",
            "Iteration:  27% 201/743 [00:26<01:09,  7.81it/s]\u001b[A\n",
            "Iteration:  27% 202/743 [00:26<01:09,  7.80it/s]\u001b[A\n",
            "Iteration:  27% 203/743 [00:27<01:09,  7.81it/s]\u001b[A\n",
            "Iteration:  27% 204/743 [00:27<01:09,  7.77it/s]\u001b[A\n",
            "Iteration:  28% 205/743 [00:27<01:09,  7.78it/s]\u001b[A\n",
            "Iteration:  28% 206/743 [00:27<01:08,  7.79it/s]\u001b[A\n",
            "Iteration:  28% 207/743 [00:27<01:08,  7.80it/s]\u001b[A\n",
            "Iteration:  28% 208/743 [00:27<01:08,  7.81it/s]\u001b[A\n",
            "Iteration:  28% 209/743 [00:27<01:08,  7.82it/s]\u001b[A\n",
            "Iteration:  28% 210/743 [00:27<01:08,  7.81it/s]\u001b[A\n",
            "Iteration:  28% 211/743 [00:28<01:08,  7.80it/s]\u001b[A\n",
            "Iteration:  29% 212/743 [00:28<01:08,  7.79it/s]\u001b[A\n",
            "Iteration:  29% 213/743 [00:28<01:09,  7.65it/s]\u001b[A\n",
            "Iteration:  29% 214/743 [00:28<01:08,  7.69it/s]\u001b[A\n",
            "Iteration:  29% 215/743 [00:28<01:08,  7.73it/s]\u001b[A\n",
            "Iteration:  29% 216/743 [00:28<01:07,  7.76it/s]\u001b[A\n",
            "Iteration:  29% 217/743 [00:28<01:07,  7.77it/s]\u001b[A\n",
            "Iteration:  29% 218/743 [00:29<01:07,  7.78it/s]\u001b[A\n",
            "Iteration:  29% 219/743 [00:29<01:08,  7.70it/s]\u001b[A\n",
            "Iteration:  30% 220/743 [00:29<01:07,  7.72it/s]\u001b[A\n",
            "Iteration:  30% 221/743 [00:29<01:07,  7.72it/s]\u001b[A\n",
            "Iteration:  30% 222/743 [00:29<01:07,  7.77it/s]\u001b[A\n",
            "Iteration:  30% 223/743 [00:29<01:06,  7.79it/s]\u001b[A\n",
            "Iteration:  30% 224/743 [00:29<01:06,  7.81it/s]\u001b[A\n",
            "Iteration:  30% 225/743 [00:29<01:06,  7.79it/s]\u001b[A\n",
            "Iteration:  30% 226/743 [00:30<01:06,  7.80it/s]\u001b[A\n",
            "Iteration:  31% 227/743 [00:30<01:06,  7.81it/s]\u001b[A\n",
            "Iteration:  31% 228/743 [00:30<01:05,  7.81it/s]\u001b[A\n",
            "Iteration:  31% 229/743 [00:30<01:05,  7.81it/s]\u001b[A\n",
            "Iteration:  31% 230/743 [00:30<01:05,  7.81it/s]\u001b[A\n",
            "Iteration:  31% 231/743 [00:30<01:05,  7.81it/s]\u001b[A\n",
            "Iteration:  31% 232/743 [00:30<01:05,  7.82it/s]\u001b[A\n",
            "Iteration:  31% 233/743 [00:30<01:05,  7.83it/s]\u001b[A\n",
            "Iteration:  31% 234/743 [00:31<01:04,  7.84it/s]\u001b[A\n",
            "Iteration:  32% 235/743 [00:31<01:04,  7.84it/s]\u001b[A\n",
            "Iteration:  32% 236/743 [00:31<01:05,  7.80it/s]\u001b[A\n",
            "Iteration:  32% 237/743 [00:31<01:04,  7.81it/s]\u001b[A\n",
            "Iteration:  32% 238/743 [00:31<01:04,  7.81it/s]\u001b[A\n",
            "Iteration:  32% 239/743 [00:31<01:04,  7.82it/s]\u001b[A\n",
            "Iteration:  32% 240/743 [00:31<01:04,  7.83it/s]\u001b[A\n",
            "Iteration:  32% 241/743 [00:31<01:04,  7.80it/s]\u001b[A\n",
            "Iteration:  33% 242/743 [00:32<01:04,  7.75it/s]\u001b[A\n",
            "Iteration:  33% 243/743 [00:32<01:04,  7.78it/s]\u001b[A\n",
            "Iteration:  33% 244/743 [00:32<01:04,  7.79it/s]\u001b[A\n",
            "Iteration:  33% 245/743 [00:32<01:03,  7.81it/s]\u001b[A\n",
            "Iteration:  33% 246/743 [00:32<01:03,  7.82it/s]\u001b[A\n",
            "Iteration:  33% 247/743 [00:32<01:03,  7.79it/s]\u001b[A\n",
            "Iteration:  33% 248/743 [00:32<01:03,  7.79it/s]\u001b[A\n",
            "Iteration:  34% 249/743 [00:33<01:03,  7.79it/s]\u001b[A\n",
            "Iteration:  34% 250/743 [00:33<01:03,  7.80it/s]\u001b[A\n",
            "Iteration:  34% 251/743 [00:33<01:03,  7.80it/s]\u001b[A\n",
            "Iteration:  34% 252/743 [00:33<01:02,  7.82it/s]\u001b[A\n",
            "Iteration:  34% 253/743 [00:33<01:02,  7.81it/s]\u001b[A\n",
            "Iteration:  34% 254/743 [00:33<01:02,  7.81it/s]\u001b[A\n",
            "Iteration:  34% 255/743 [00:33<01:02,  7.82it/s]\u001b[A\n",
            "Iteration:  34% 256/743 [00:33<01:02,  7.84it/s]\u001b[A\n",
            "Iteration:  35% 257/743 [00:34<01:02,  7.82it/s]\u001b[A\n",
            "Iteration:  35% 258/743 [00:34<01:02,  7.80it/s]\u001b[A\n",
            "Iteration:  35% 259/743 [00:34<01:02,  7.79it/s]\u001b[A\n",
            "Iteration:  35% 260/743 [00:34<01:02,  7.78it/s]\u001b[A\n",
            "Iteration:  35% 261/743 [00:34<01:01,  7.78it/s]\u001b[A\n",
            "Iteration:  35% 262/743 [00:34<01:01,  7.80it/s]\u001b[A\n",
            "Iteration:  35% 263/743 [00:34<01:01,  7.81it/s]\u001b[A\n",
            "Iteration:  36% 264/743 [00:34<01:01,  7.80it/s]\u001b[A\n",
            "Iteration:  36% 265/743 [00:35<01:01,  7.81it/s]\u001b[A\n",
            "Iteration:  36% 266/743 [00:35<01:01,  7.82it/s]\u001b[A\n",
            "Iteration:  36% 267/743 [00:35<01:00,  7.83it/s]\u001b[A\n",
            "Iteration:  36% 268/743 [00:35<01:00,  7.83it/s]\u001b[A\n",
            "Iteration:  36% 269/743 [00:35<01:00,  7.85it/s]\u001b[A\n",
            "Iteration:  36% 270/743 [00:35<01:00,  7.84it/s]\u001b[A\n",
            "Iteration:  36% 271/743 [00:35<01:00,  7.78it/s]\u001b[A\n",
            "Iteration:  37% 272/743 [00:35<01:00,  7.81it/s]\u001b[A\n",
            "Iteration:  37% 273/743 [00:36<01:00,  7.83it/s]\u001b[A\n",
            "Iteration:  37% 274/743 [00:36<00:59,  7.83it/s]\u001b[A\n",
            "Iteration:  37% 275/743 [00:36<00:59,  7.83it/s]\u001b[A\n",
            "Iteration:  37% 276/743 [00:36<01:00,  7.67it/s]\u001b[A\n",
            "Iteration:  37% 277/743 [00:36<01:00,  7.73it/s]\u001b[A\n",
            "Iteration:  37% 278/743 [00:36<00:59,  7.78it/s]\u001b[A\n",
            "Iteration:  38% 279/743 [00:36<00:59,  7.79it/s]\u001b[A\n",
            "Iteration:  38% 280/743 [00:36<00:59,  7.81it/s]\u001b[A\n",
            "Iteration:  38% 281/743 [00:37<00:58,  7.83it/s]\u001b[A\n",
            "Iteration:  38% 282/743 [00:37<00:58,  7.83it/s]\u001b[A\n",
            "Iteration:  38% 283/743 [00:37<00:58,  7.84it/s]\u001b[A\n",
            "Iteration:  38% 284/743 [00:37<00:58,  7.85it/s]\u001b[A\n",
            "Iteration:  38% 285/743 [00:37<00:58,  7.84it/s]\u001b[A\n",
            "Iteration:  38% 286/743 [00:37<00:58,  7.84it/s]\u001b[A\n",
            "Iteration:  39% 287/743 [00:37<00:58,  7.84it/s]\u001b[A\n",
            "Iteration:  39% 288/743 [00:37<00:58,  7.84it/s]\u001b[A\n",
            "Iteration:  39% 289/743 [00:38<00:57,  7.84it/s]\u001b[A\n",
            "Iteration:  39% 290/743 [00:38<00:58,  7.78it/s]\u001b[A\n",
            "Iteration:  39% 291/743 [00:38<00:58,  7.79it/s]\u001b[A\n",
            "Iteration:  39% 292/743 [00:38<00:59,  7.53it/s]\u001b[A\n",
            "Iteration:  39% 293/743 [00:38<00:59,  7.61it/s]\u001b[A\n",
            "Iteration:  40% 294/743 [00:38<00:58,  7.69it/s]\u001b[A\n",
            "Iteration:  40% 295/743 [00:38<00:57,  7.74it/s]\u001b[A\n",
            "Iteration:  40% 296/743 [00:39<00:57,  7.78it/s]\u001b[A\n",
            "Iteration:  40% 297/743 [00:39<00:57,  7.80it/s]\u001b[A\n",
            "Iteration:  40% 298/743 [00:39<00:56,  7.81it/s]\u001b[A\n",
            "Iteration:  40% 299/743 [00:39<00:56,  7.79it/s]\u001b[A\n",
            "Iteration:  40% 300/743 [00:39<00:57,  7.71it/s]\u001b[A\n",
            "Iteration:  41% 301/743 [00:39<00:57,  7.75it/s]\u001b[A\n",
            "Iteration:  41% 302/743 [00:39<00:56,  7.78it/s]\u001b[A\n",
            "Iteration:  41% 303/743 [00:39<00:56,  7.81it/s]\u001b[A\n",
            "Iteration:  41% 304/743 [00:40<00:56,  7.80it/s]\u001b[A\n",
            "Iteration:  41% 305/743 [00:40<00:56,  7.81it/s]\u001b[A\n",
            "Iteration:  41% 306/743 [00:40<00:55,  7.81it/s]\u001b[A\n",
            "Iteration:  41% 307/743 [00:40<00:55,  7.80it/s]\u001b[A\n",
            "Iteration:  41% 308/743 [00:40<00:56,  7.69it/s]\u001b[A\n",
            "Iteration:  42% 309/743 [00:40<00:56,  7.74it/s]\u001b[A\n",
            "Iteration:  42% 310/743 [00:40<00:55,  7.77it/s]\u001b[A\n",
            "Iteration:  42% 311/743 [00:40<00:55,  7.78it/s]\u001b[A\n",
            "Iteration:  42% 312/743 [00:41<00:55,  7.80it/s]\u001b[A\n",
            "Iteration:  42% 313/743 [00:41<00:54,  7.82it/s]\u001b[A\n",
            "Iteration:  42% 314/743 [00:41<00:54,  7.83it/s]\u001b[A\n",
            "Iteration:  42% 315/743 [00:41<00:54,  7.80it/s]\u001b[A\n",
            "Iteration:  43% 316/743 [00:41<00:54,  7.81it/s]\u001b[A\n",
            "Iteration:  43% 317/743 [00:41<00:54,  7.82it/s]\u001b[A\n",
            "Iteration:  43% 318/743 [00:41<00:54,  7.84it/s]\u001b[A\n",
            "Iteration:  43% 319/743 [00:41<00:54,  7.83it/s]\u001b[A\n",
            "Iteration:  43% 320/743 [00:42<00:54,  7.83it/s]\u001b[A\n",
            "Iteration:  43% 321/743 [00:42<00:54,  7.75it/s]\u001b[A\n",
            "Iteration:  43% 322/743 [00:42<00:54,  7.76it/s]\u001b[A\n",
            "Iteration:  43% 323/743 [00:42<00:54,  7.76it/s]\u001b[A\n",
            "Iteration:  44% 324/743 [00:42<00:53,  7.77it/s]\u001b[A\n",
            "Iteration:  44% 325/743 [00:42<00:53,  7.79it/s]\u001b[A\n",
            "Iteration:  44% 326/743 [00:42<00:53,  7.81it/s]\u001b[A\n",
            "Iteration:  44% 327/743 [00:43<00:53,  7.82it/s]\u001b[A\n",
            "Iteration:  44% 328/743 [00:43<00:53,  7.82it/s]\u001b[A\n",
            "Iteration:  44% 329/743 [00:43<00:52,  7.82it/s]\u001b[A\n",
            "Iteration:  44% 330/743 [00:43<00:53,  7.70it/s]\u001b[A\n",
            "Iteration:  45% 331/743 [00:43<00:53,  7.73it/s]\u001b[A\n",
            "Iteration:  45% 332/743 [00:43<00:53,  7.72it/s]\u001b[A\n",
            "Iteration:  45% 333/743 [00:43<00:52,  7.75it/s]\u001b[A\n",
            "Iteration:  45% 334/743 [00:43<00:52,  7.78it/s]\u001b[A\n",
            "Iteration:  45% 335/743 [00:44<00:52,  7.74it/s]\u001b[A\n",
            "Iteration:  45% 336/743 [00:44<00:52,  7.75it/s]\u001b[A\n",
            "Iteration:  45% 337/743 [00:44<00:52,  7.75it/s]\u001b[A\n",
            "Iteration:  45% 338/743 [00:44<00:52,  7.75it/s]\u001b[A\n",
            "Iteration:  46% 339/743 [00:44<00:52,  7.76it/s]\u001b[A\n",
            "Iteration:  46% 340/743 [00:44<00:51,  7.77it/s]\u001b[A\n",
            "Iteration:  46% 341/743 [00:44<00:51,  7.77it/s]\u001b[A\n",
            "Iteration:  46% 342/743 [00:44<00:51,  7.78it/s]\u001b[A\n",
            "Iteration:  46% 343/743 [00:45<00:51,  7.77it/s]\u001b[A\n",
            "Iteration:  46% 344/743 [00:45<00:51,  7.78it/s]\u001b[A\n",
            "Iteration:  46% 345/743 [00:45<00:51,  7.76it/s]\u001b[A\n",
            "Iteration:  47% 346/743 [00:45<00:51,  7.76it/s]\u001b[A\n",
            "Iteration:  47% 347/743 [00:45<00:51,  7.73it/s]\u001b[A\n",
            "Iteration:  47% 348/743 [00:45<00:51,  7.74it/s]\u001b[A\n",
            "Iteration:  47% 349/743 [00:45<00:50,  7.73it/s]\u001b[A\n",
            "Iteration:  47% 350/743 [00:45<00:50,  7.72it/s]\u001b[A\n",
            "Iteration:  47% 351/743 [00:46<00:50,  7.72it/s]\u001b[A\n",
            "Iteration:  47% 352/743 [00:46<00:50,  7.72it/s]\u001b[A\n",
            "Iteration:  48% 353/743 [00:46<00:50,  7.73it/s]\u001b[A\n",
            "Iteration:  48% 354/743 [00:46<00:50,  7.72it/s]\u001b[A\n",
            "Iteration:  48% 355/743 [00:46<00:50,  7.72it/s]\u001b[A\n",
            "Iteration:  48% 356/743 [00:46<00:50,  7.72it/s]\u001b[A\n",
            "Iteration:  48% 357/743 [00:46<00:50,  7.71it/s]\u001b[A\n",
            "Iteration:  48% 358/743 [00:47<00:49,  7.73it/s]\u001b[A\n",
            "Iteration:  48% 359/743 [00:47<00:49,  7.73it/s]\u001b[A\n",
            "Iteration:  48% 360/743 [00:47<00:50,  7.61it/s]\u001b[A\n",
            "Iteration:  49% 361/743 [00:47<00:50,  7.53it/s]\u001b[A\n",
            "Iteration:  49% 362/743 [00:47<00:50,  7.59it/s]\u001b[A\n",
            "Iteration:  49% 363/743 [00:47<00:49,  7.67it/s]\u001b[A\n",
            "Iteration:  49% 364/743 [00:47<00:49,  7.73it/s]\u001b[A\n",
            "Iteration:  49% 365/743 [00:47<00:48,  7.77it/s]\u001b[A\n",
            "Iteration:  49% 366/743 [00:48<00:48,  7.79it/s]\u001b[A\n",
            "Iteration:  49% 367/743 [00:48<00:48,  7.81it/s]\u001b[A\n",
            "Iteration:  50% 368/743 [00:48<00:47,  7.82it/s]\u001b[A\n",
            "Iteration:  50% 369/743 [00:48<00:47,  7.83it/s]\u001b[A\n",
            "Iteration:  50% 370/743 [00:48<00:47,  7.82it/s]\u001b[A\n",
            "Iteration:  50% 371/743 [00:48<00:47,  7.83it/s]\u001b[A\n",
            "Iteration:  50% 372/743 [00:48<00:47,  7.84it/s]\u001b[A\n",
            "Iteration:  50% 373/743 [00:48<00:47,  7.84it/s]\u001b[A\n",
            "Iteration:  50% 374/743 [00:49<00:46,  7.85it/s]\u001b[A\n",
            "Iteration:  50% 375/743 [00:49<00:46,  7.86it/s]\u001b[A\n",
            "Iteration:  51% 376/743 [00:49<00:46,  7.86it/s]\u001b[A\n",
            "Iteration:  51% 377/743 [00:49<00:46,  7.84it/s]\u001b[A\n",
            "Iteration:  51% 378/743 [00:49<00:46,  7.86it/s]\u001b[A\n",
            "Iteration:  51% 379/743 [00:49<00:46,  7.84it/s]\u001b[A\n",
            "Iteration:  51% 380/743 [00:49<00:46,  7.83it/s]\u001b[A\n",
            "Iteration:  51% 381/743 [00:49<00:46,  7.84it/s]\u001b[A\n",
            "Iteration:  51% 382/743 [00:50<00:46,  7.84it/s]\u001b[A\n",
            "Iteration:  52% 383/743 [00:50<00:45,  7.83it/s]\u001b[A\n",
            "Iteration:  52% 384/743 [00:50<00:45,  7.84it/s]\u001b[A\n",
            "Iteration:  52% 385/743 [00:50<00:45,  7.84it/s]\u001b[A\n",
            "Iteration:  52% 386/743 [00:50<00:45,  7.85it/s]\u001b[A\n",
            "Iteration:  52% 387/743 [00:50<00:45,  7.85it/s]\u001b[A\n",
            "Iteration:  52% 388/743 [00:50<00:45,  7.86it/s]\u001b[A\n",
            "Iteration:  52% 389/743 [00:50<00:45,  7.86it/s]\u001b[A\n",
            "Iteration:  52% 390/743 [00:51<00:44,  7.86it/s]\u001b[A\n",
            "Iteration:  53% 391/743 [00:51<00:44,  7.85it/s]\u001b[A\n",
            "Iteration:  53% 392/743 [00:51<00:44,  7.84it/s]\u001b[A\n",
            "Iteration:  53% 393/743 [00:51<00:44,  7.84it/s]\u001b[A\n",
            "Iteration:  53% 394/743 [00:51<00:44,  7.84it/s]\u001b[A\n",
            "Iteration:  53% 395/743 [00:51<00:44,  7.81it/s]\u001b[A\n",
            "Iteration:  53% 396/743 [00:51<00:44,  7.82it/s]\u001b[A\n",
            "Iteration:  53% 397/743 [00:52<00:44,  7.80it/s]\u001b[A\n",
            "Iteration:  54% 398/743 [00:52<00:44,  7.81it/s]\u001b[A\n",
            "Iteration:  54% 399/743 [00:52<00:44,  7.81it/s]\u001b[A\n",
            "Iteration:  54% 400/743 [00:52<00:43,  7.82it/s]\u001b[A\n",
            "Iteration:  54% 401/743 [00:52<00:43,  7.82it/s]\u001b[A\n",
            "Iteration:  54% 402/743 [00:52<00:43,  7.82it/s]\u001b[A\n",
            "Iteration:  54% 403/743 [00:52<00:43,  7.81it/s]\u001b[A\n",
            "Iteration:  54% 404/743 [00:52<00:43,  7.82it/s]\u001b[A\n",
            "Iteration:  55% 405/743 [00:53<00:43,  7.82it/s]\u001b[A\n",
            "Iteration:  55% 406/743 [00:53<00:43,  7.81it/s]\u001b[A\n",
            "Iteration:  55% 407/743 [00:53<00:43,  7.78it/s]\u001b[A\n",
            "Iteration:  55% 408/743 [00:53<00:42,  7.82it/s]\u001b[A\n",
            "Iteration:  55% 409/743 [00:53<00:42,  7.84it/s]\u001b[A\n",
            "Iteration:  55% 410/743 [00:53<00:42,  7.86it/s]\u001b[A\n",
            "Iteration:  55% 411/743 [00:53<00:42,  7.86it/s]\u001b[A\n",
            "Iteration:  55% 412/743 [00:53<00:42,  7.84it/s]\u001b[A\n",
            "Iteration:  56% 413/743 [00:54<00:42,  7.83it/s]\u001b[A\n",
            "Iteration:  56% 414/743 [00:54<00:41,  7.84it/s]\u001b[A\n",
            "Iteration:  56% 415/743 [00:54<00:41,  7.85it/s]\u001b[A\n",
            "Iteration:  56% 416/743 [00:54<00:41,  7.85it/s]\u001b[A\n",
            "Iteration:  56% 417/743 [00:54<00:41,  7.79it/s]\u001b[A\n",
            "Iteration:  56% 418/743 [00:54<00:41,  7.80it/s]\u001b[A\n",
            "Iteration:  56% 419/743 [00:54<00:41,  7.80it/s]\u001b[A\n",
            "Iteration:  57% 420/743 [00:54<00:41,  7.82it/s]\u001b[A\n",
            "Iteration:  57% 421/743 [00:55<00:41,  7.83it/s]\u001b[A\n",
            "Iteration:  57% 422/743 [00:55<00:40,  7.83it/s]\u001b[A\n",
            "Iteration:  57% 423/743 [00:55<00:40,  7.83it/s]\u001b[A\n",
            "Iteration:  57% 424/743 [00:55<00:40,  7.82it/s]\u001b[A\n",
            "Iteration:  57% 425/743 [00:55<00:40,  7.82it/s]\u001b[A\n",
            "Iteration:  57% 426/743 [00:55<00:40,  7.82it/s]\u001b[A\n",
            "Iteration:  57% 427/743 [00:55<00:40,  7.82it/s]\u001b[A\n",
            "Iteration:  58% 428/743 [00:55<00:40,  7.81it/s]\u001b[A\n",
            "Iteration:  58% 429/743 [00:56<00:40,  7.82it/s]\u001b[A\n",
            "Iteration:  58% 430/743 [00:56<00:40,  7.81it/s]\u001b[A\n",
            "Iteration:  58% 431/743 [00:56<00:40,  7.79it/s]\u001b[A\n",
            "Iteration:  58% 432/743 [00:56<00:39,  7.78it/s]\u001b[A\n",
            "Iteration:  58% 433/743 [00:56<00:39,  7.80it/s]\u001b[A\n",
            "Iteration:  58% 434/743 [00:56<00:39,  7.82it/s]\u001b[A\n",
            "Iteration:  59% 435/743 [00:56<00:39,  7.83it/s]\u001b[A\n",
            "Iteration:  59% 436/743 [00:57<00:39,  7.80it/s]\u001b[A\n",
            "Iteration:  59% 437/743 [00:57<00:39,  7.79it/s]\u001b[A\n",
            "Iteration:  59% 438/743 [00:57<00:39,  7.79it/s]\u001b[A\n",
            "Iteration:  59% 439/743 [00:57<00:39,  7.77it/s]\u001b[A\n",
            "Iteration:  59% 440/743 [00:57<00:39,  7.73it/s]\u001b[A\n",
            "Iteration:  59% 441/743 [00:57<00:39,  7.74it/s]\u001b[A\n",
            "Iteration:  59% 442/743 [00:57<00:38,  7.76it/s]\u001b[A\n",
            "Iteration:  60% 443/743 [00:57<00:38,  7.78it/s]\u001b[A\n",
            "Iteration:  60% 444/743 [00:58<00:38,  7.77it/s]\u001b[A\n",
            "Iteration:  60% 445/743 [00:58<00:38,  7.78it/s]\u001b[A\n",
            "Iteration:  60% 446/743 [00:58<00:38,  7.80it/s]\u001b[A\n",
            "Iteration:  60% 447/743 [00:58<00:37,  7.80it/s]\u001b[A\n",
            "Iteration:  60% 448/743 [00:58<00:37,  7.80it/s]\u001b[A\n",
            "Iteration:  60% 449/743 [00:58<00:37,  7.81it/s]\u001b[A\n",
            "Iteration:  61% 450/743 [00:58<00:37,  7.81it/s]\u001b[A\n",
            "Iteration:  61% 451/743 [00:58<00:37,  7.81it/s]\u001b[A\n",
            "Iteration:  61% 452/743 [00:59<00:37,  7.80it/s]\u001b[A\n",
            "Iteration:  61% 453/743 [00:59<00:37,  7.79it/s]\u001b[A\n",
            "Iteration:  61% 454/743 [00:59<00:37,  7.77it/s]\u001b[A\n",
            "Iteration:  61% 455/743 [00:59<00:36,  7.79it/s]\u001b[A\n",
            "Iteration:  61% 456/743 [00:59<00:36,  7.81it/s]\u001b[A\n",
            "Iteration:  62% 457/743 [00:59<00:36,  7.80it/s]\u001b[A\n",
            "Iteration:  62% 458/743 [00:59<00:36,  7.79it/s]\u001b[A\n",
            "Iteration:  62% 459/743 [00:59<00:36,  7.79it/s]\u001b[A\n",
            "Iteration:  62% 460/743 [01:00<00:36,  7.80it/s]\u001b[A\n",
            "Iteration:  62% 461/743 [01:00<00:36,  7.79it/s]\u001b[A\n",
            "Iteration:  62% 462/743 [01:00<00:36,  7.76it/s]\u001b[A\n",
            "Iteration:  62% 463/743 [01:00<00:36,  7.76it/s]\u001b[A\n",
            "Iteration:  62% 464/743 [01:00<00:35,  7.77it/s]\u001b[A\n",
            "Iteration:  63% 465/743 [01:00<00:35,  7.78it/s]\u001b[A\n",
            "Iteration:  63% 466/743 [01:00<00:35,  7.78it/s]\u001b[A\n",
            "Iteration:  63% 467/743 [01:00<00:35,  7.78it/s]\u001b[A\n",
            "Iteration:  63% 468/743 [01:01<00:35,  7.80it/s]\u001b[A\n",
            "Iteration:  63% 469/743 [01:01<00:35,  7.80it/s]\u001b[A\n",
            "Iteration:  63% 470/743 [01:01<00:35,  7.67it/s]\u001b[A\n",
            "Iteration:  63% 471/743 [01:01<00:35,  7.71it/s]\u001b[A\n",
            "Iteration:  64% 472/743 [01:01<00:35,  7.74it/s]\u001b[A\n",
            "Iteration:  64% 473/743 [01:01<00:34,  7.77it/s]\u001b[A\n",
            "Iteration:  64% 474/743 [01:01<00:34,  7.79it/s]\u001b[A\n",
            "Iteration:  64% 475/743 [01:02<00:34,  7.78it/s]\u001b[A\n",
            "Iteration:  64% 476/743 [01:02<00:34,  7.80it/s]\u001b[A\n",
            "Iteration:  64% 477/743 [01:02<00:34,  7.81it/s]\u001b[A\n",
            "Iteration:  64% 478/743 [01:02<00:33,  7.83it/s]\u001b[A\n",
            "Iteration:  64% 479/743 [01:02<00:33,  7.83it/s]\u001b[A\n",
            "Iteration:  65% 480/743 [01:02<00:33,  7.83it/s]\u001b[A\n",
            "Iteration:  65% 481/743 [01:02<00:33,  7.84it/s]\u001b[A\n",
            "Iteration:  65% 482/743 [01:02<00:33,  7.83it/s]\u001b[A\n",
            "Iteration:  65% 483/743 [01:03<00:33,  7.83it/s]\u001b[A\n",
            "Iteration:  65% 484/743 [01:03<00:33,  7.84it/s]\u001b[A\n",
            "Iteration:  65% 485/743 [01:03<00:32,  7.84it/s]\u001b[A\n",
            "Iteration:  65% 486/743 [01:03<00:32,  7.84it/s]\u001b[A\n",
            "Iteration:  66% 487/743 [01:03<00:32,  7.84it/s]\u001b[A\n",
            "Iteration:  66% 488/743 [01:03<00:32,  7.84it/s]\u001b[A\n",
            "Iteration:  66% 489/743 [01:03<00:32,  7.85it/s]\u001b[A\n",
            "Iteration:  66% 490/743 [01:03<00:32,  7.83it/s]\u001b[A\n",
            "Iteration:  66% 491/743 [01:04<00:32,  7.82it/s]\u001b[A\n",
            "Iteration:  66% 492/743 [01:04<00:32,  7.83it/s]\u001b[A\n",
            "Iteration:  66% 493/743 [01:04<00:31,  7.82it/s]\u001b[A\n",
            "Iteration:  66% 494/743 [01:04<00:31,  7.81it/s]\u001b[A\n",
            "Iteration:  67% 495/743 [01:04<00:31,  7.82it/s]\u001b[A\n",
            "Iteration:  67% 496/743 [01:04<00:31,  7.81it/s]\u001b[A\n",
            "Iteration:  67% 497/743 [01:04<00:31,  7.81it/s]\u001b[A\n",
            "Iteration:  67% 498/743 [01:04<00:31,  7.80it/s]\u001b[A\n",
            "Iteration:  67% 499/743 [01:05<00:31,  7.80it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:271: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "05/20/2024 18:49:04 - INFO - __main__ -   Saving model checkpoint to model_write_path/checkpoint-500\n",
            "05/20/2024 18:49:22 - INFO - __main__ -   Saving optimizer and scheduler states to model_write_path/checkpoint-500\n",
            "\n",
            "Iteration:  67% 500/743 [01:31<32:49,  8.11s/it]\u001b[A\n",
            "Iteration:  67% 501/743 [01:31<23:03,  5.72s/it]\u001b[A\n",
            "Iteration:  68% 502/743 [01:32<16:14,  4.04s/it]\u001b[A\n",
            "Iteration:  68% 503/743 [01:32<11:28,  2.87s/it]\u001b[A\n",
            "Iteration:  68% 504/743 [01:32<08:09,  2.05s/it]\u001b[A\n",
            "Iteration:  68% 505/743 [01:32<05:50,  1.47s/it]\u001b[A\n",
            "Iteration:  68% 506/743 [01:32<04:13,  1.07s/it]\u001b[A\n",
            "Iteration:  68% 507/743 [01:32<03:05,  1.27it/s]\u001b[A\n",
            "Iteration:  68% 508/743 [01:32<02:18,  1.70it/s]\u001b[A\n",
            "Iteration:  69% 509/743 [01:32<01:45,  2.22it/s]\u001b[A\n",
            "Iteration:  69% 510/743 [01:33<01:22,  2.83it/s]\u001b[A\n",
            "Iteration:  69% 511/743 [01:33<01:06,  3.50it/s]\u001b[A\n",
            "Iteration:  69% 512/743 [01:33<00:55,  4.19it/s]\u001b[A\n",
            "Iteration:  69% 513/743 [01:33<00:47,  4.87it/s]\u001b[A\n",
            "Iteration:  69% 514/743 [01:33<00:41,  5.50it/s]\u001b[A\n",
            "Iteration:  69% 515/743 [01:33<00:37,  6.04it/s]\u001b[A\n",
            "Iteration:  69% 516/743 [01:33<00:34,  6.49it/s]\u001b[A\n",
            "Iteration:  70% 517/743 [01:33<00:32,  6.85it/s]\u001b[A\n",
            "Iteration:  70% 518/743 [01:34<00:31,  7.12it/s]\u001b[A\n",
            "Iteration:  70% 519/743 [01:34<00:30,  7.32it/s]\u001b[A\n",
            "Iteration:  70% 520/743 [01:34<00:29,  7.46it/s]\u001b[A\n",
            "Iteration:  70% 521/743 [01:34<00:29,  7.57it/s]\u001b[A\n",
            "Iteration:  70% 522/743 [01:34<00:28,  7.64it/s]\u001b[A\n",
            "Iteration:  70% 523/743 [01:34<00:28,  7.65it/s]\u001b[A\n",
            "Iteration:  71% 524/743 [01:34<00:28,  7.68it/s]\u001b[A\n",
            "Iteration:  71% 525/743 [01:35<00:28,  7.69it/s]\u001b[A\n",
            "Iteration:  71% 526/743 [01:35<00:28,  7.71it/s]\u001b[A\n",
            "Iteration:  71% 527/743 [01:35<00:27,  7.73it/s]\u001b[A\n",
            "Iteration:  71% 528/743 [01:35<00:27,  7.75it/s]\u001b[A\n",
            "Iteration:  71% 529/743 [01:35<00:27,  7.78it/s]\u001b[A\n",
            "Iteration:  71% 530/743 [01:35<00:27,  7.80it/s]\u001b[A\n",
            "Iteration:  71% 531/743 [01:35<00:27,  7.81it/s]\u001b[A\n",
            "Iteration:  72% 532/743 [01:35<00:27,  7.81it/s]\u001b[A\n",
            "Iteration:  72% 533/743 [01:36<00:26,  7.81it/s]\u001b[A\n",
            "Iteration:  72% 534/743 [01:36<00:26,  7.77it/s]\u001b[A\n",
            "Iteration:  72% 535/743 [01:36<00:26,  7.75it/s]\u001b[A\n",
            "Iteration:  72% 536/743 [01:36<00:26,  7.73it/s]\u001b[A\n",
            "Iteration:  72% 537/743 [01:36<00:26,  7.72it/s]\u001b[A\n",
            "Iteration:  72% 538/743 [01:36<00:26,  7.77it/s]\u001b[A\n",
            "Iteration:  73% 539/743 [01:36<00:26,  7.79it/s]\u001b[A\n",
            "Iteration:  73% 540/743 [01:36<00:26,  7.79it/s]\u001b[A\n",
            "Iteration:  73% 541/743 [01:37<00:25,  7.79it/s]\u001b[A\n",
            "Iteration:  73% 542/743 [01:37<00:25,  7.81it/s]\u001b[A\n",
            "Iteration:  73% 543/743 [01:37<00:25,  7.82it/s]\u001b[A\n",
            "Iteration:  73% 544/743 [01:37<00:25,  7.82it/s]\u001b[A\n",
            "Iteration:  73% 545/743 [01:37<00:25,  7.82it/s]\u001b[A\n",
            "Iteration:  73% 546/743 [01:37<00:25,  7.83it/s]\u001b[A\n",
            "Iteration:  74% 547/743 [01:37<00:25,  7.84it/s]\u001b[A\n",
            "Iteration:  74% 548/743 [01:37<00:24,  7.85it/s]\u001b[A\n",
            "Iteration:  74% 549/743 [01:38<00:24,  7.86it/s]\u001b[A\n",
            "Iteration:  74% 550/743 [01:38<00:24,  7.86it/s]\u001b[A\n",
            "Iteration:  74% 551/743 [01:38<00:24,  7.86it/s]\u001b[A\n",
            "Iteration:  74% 552/743 [01:38<00:24,  7.85it/s]\u001b[A\n",
            "Iteration:  74% 553/743 [01:38<00:24,  7.85it/s]\u001b[A\n",
            "Iteration:  75% 554/743 [01:38<00:24,  7.86it/s]\u001b[A\n",
            "Iteration:  75% 555/743 [01:38<00:23,  7.86it/s]\u001b[A\n",
            "Iteration:  75% 556/743 [01:38<00:23,  7.87it/s]\u001b[A\n",
            "Iteration:  75% 557/743 [01:39<00:23,  7.88it/s]\u001b[A\n",
            "Iteration:  75% 558/743 [01:39<00:23,  7.87it/s]\u001b[A\n",
            "Iteration:  75% 559/743 [01:39<00:23,  7.87it/s]\u001b[A\n",
            "Iteration:  75% 560/743 [01:39<00:23,  7.86it/s]\u001b[A\n",
            "Iteration:  76% 561/743 [01:39<00:23,  7.85it/s]\u001b[A\n",
            "Iteration:  76% 562/743 [01:39<00:23,  7.84it/s]\u001b[A\n",
            "Iteration:  76% 563/743 [01:39<00:22,  7.84it/s]\u001b[A\n",
            "Iteration:  76% 564/743 [01:40<00:22,  7.85it/s]\u001b[A\n",
            "Iteration:  76% 565/743 [01:40<00:22,  7.86it/s]\u001b[A\n",
            "Iteration:  76% 566/743 [01:40<00:22,  7.80it/s]\u001b[A\n",
            "Iteration:  76% 567/743 [01:40<00:22,  7.74it/s]\u001b[A\n",
            "Iteration:  76% 568/743 [01:40<00:22,  7.77it/s]\u001b[A\n",
            "Iteration:  77% 569/743 [01:40<00:22,  7.77it/s]\u001b[A\n",
            "Iteration:  77% 570/743 [01:40<00:22,  7.80it/s]\u001b[A\n",
            "Iteration:  77% 571/743 [01:40<00:21,  7.82it/s]\u001b[A\n",
            "Iteration:  77% 572/743 [01:41<00:21,  7.80it/s]\u001b[A\n",
            "Iteration:  77% 573/743 [01:41<00:21,  7.81it/s]\u001b[A\n",
            "Iteration:  77% 574/743 [01:41<00:21,  7.83it/s]\u001b[A\n",
            "Iteration:  77% 575/743 [01:41<00:21,  7.82it/s]\u001b[A\n",
            "Iteration:  78% 576/743 [01:41<00:21,  7.83it/s]\u001b[A\n",
            "Iteration:  78% 577/743 [01:41<00:21,  7.81it/s]\u001b[A\n",
            "Iteration:  78% 578/743 [01:41<00:21,  7.83it/s]\u001b[A\n",
            "Iteration:  78% 579/743 [01:41<00:20,  7.85it/s]\u001b[A\n",
            "Iteration:  78% 580/743 [01:42<00:20,  7.85it/s]\u001b[A\n",
            "Iteration:  78% 581/743 [01:42<00:20,  7.86it/s]\u001b[A\n",
            "Iteration:  78% 582/743 [01:42<00:20,  7.82it/s]\u001b[A\n",
            "Iteration:  78% 583/743 [01:42<00:20,  7.83it/s]\u001b[A\n",
            "Iteration:  79% 584/743 [01:42<00:20,  7.83it/s]\u001b[A\n",
            "Iteration:  79% 585/743 [01:42<00:20,  7.75it/s]\u001b[A\n",
            "Iteration:  79% 586/743 [01:42<00:20,  7.77it/s]\u001b[A\n",
            "Iteration:  79% 587/743 [01:42<00:20,  7.80it/s]\u001b[A\n",
            "Iteration:  79% 588/743 [01:43<00:19,  7.79it/s]\u001b[A\n",
            "Iteration:  79% 589/743 [01:43<00:19,  7.79it/s]\u001b[A\n",
            "Iteration:  79% 590/743 [01:43<00:19,  7.80it/s]\u001b[A\n",
            "Iteration:  80% 591/743 [01:43<00:19,  7.82it/s]\u001b[A\n",
            "Iteration:  80% 592/743 [01:43<00:19,  7.83it/s]\u001b[A\n",
            "Iteration:  80% 593/743 [01:43<00:19,  7.79it/s]\u001b[A\n",
            "Iteration:  80% 594/743 [01:43<00:19,  7.82it/s]\u001b[A\n",
            "Iteration:  80% 595/743 [01:43<00:18,  7.83it/s]\u001b[A\n",
            "Iteration:  80% 596/743 [01:44<00:18,  7.79it/s]\u001b[A\n",
            "Iteration:  80% 597/743 [01:44<00:18,  7.80it/s]\u001b[A\n",
            "Iteration:  80% 598/743 [01:44<00:18,  7.81it/s]\u001b[A\n",
            "Iteration:  81% 599/743 [01:44<00:18,  7.82it/s]\u001b[A\n",
            "Iteration:  81% 600/743 [01:44<00:18,  7.83it/s]\u001b[A\n",
            "Iteration:  81% 601/743 [01:44<00:18,  7.80it/s]\u001b[A\n",
            "Iteration:  81% 602/743 [01:44<00:18,  7.80it/s]\u001b[A\n",
            "Iteration:  81% 603/743 [01:45<00:17,  7.81it/s]\u001b[A\n",
            "Iteration:  81% 604/743 [01:45<00:17,  7.82it/s]\u001b[A\n",
            "Iteration:  81% 605/743 [01:45<00:17,  7.83it/s]\u001b[A\n",
            "Iteration:  82% 606/743 [01:45<00:17,  7.82it/s]\u001b[A\n",
            "Iteration:  82% 607/743 [01:45<00:17,  7.82it/s]\u001b[A\n",
            "Iteration:  82% 608/743 [01:45<00:17,  7.83it/s]\u001b[A\n",
            "Iteration:  82% 609/743 [01:45<00:17,  7.81it/s]\u001b[A\n",
            "Iteration:  82% 610/743 [01:45<00:16,  7.84it/s]\u001b[A\n",
            "Iteration:  82% 611/743 [01:46<00:16,  7.84it/s]\u001b[A\n",
            "Iteration:  82% 612/743 [01:46<00:16,  7.85it/s]\u001b[A\n",
            "Iteration:  83% 613/743 [01:46<00:16,  7.84it/s]\u001b[A\n",
            "Iteration:  83% 614/743 [01:46<00:16,  7.84it/s]\u001b[A\n",
            "Iteration:  83% 615/743 [01:46<00:16,  7.82it/s]\u001b[A\n",
            "Iteration:  83% 616/743 [01:46<00:16,  7.83it/s]\u001b[A\n",
            "Iteration:  83% 617/743 [01:46<00:16,  7.82it/s]\u001b[A\n",
            "Iteration:  83% 618/743 [01:46<00:15,  7.83it/s]\u001b[A\n",
            "Iteration:  83% 619/743 [01:47<00:15,  7.84it/s]\u001b[A\n",
            "Iteration:  83% 620/743 [01:47<00:16,  7.65it/s]\u001b[A\n",
            "Iteration:  84% 621/743 [01:47<00:15,  7.70it/s]\u001b[A\n",
            "Iteration:  84% 622/743 [01:47<00:15,  7.73it/s]\u001b[A\n",
            "Iteration:  84% 623/743 [01:47<00:15,  7.77it/s]\u001b[A\n",
            "Iteration:  84% 624/743 [01:47<00:15,  7.79it/s]\u001b[A\n",
            "Iteration:  84% 625/743 [01:47<00:15,  7.81it/s]\u001b[A\n",
            "Iteration:  84% 626/743 [01:47<00:14,  7.82it/s]\u001b[A\n",
            "Iteration:  84% 627/743 [01:48<00:14,  7.83it/s]\u001b[A\n",
            "Iteration:  85% 628/743 [01:48<00:14,  7.83it/s]\u001b[A\n",
            "Iteration:  85% 629/743 [01:48<00:14,  7.78it/s]\u001b[A\n",
            "Iteration:  85% 630/743 [01:48<00:14,  7.78it/s]\u001b[A\n",
            "Iteration:  85% 631/743 [01:48<00:14,  7.79it/s]\u001b[A\n",
            "Iteration:  85% 632/743 [01:48<00:14,  7.80it/s]\u001b[A\n",
            "Iteration:  85% 633/743 [01:48<00:14,  7.80it/s]\u001b[A\n",
            "Iteration:  85% 634/743 [01:48<00:13,  7.81it/s]\u001b[A\n",
            "Iteration:  85% 635/743 [01:49<00:13,  7.83it/s]\u001b[A\n",
            "Iteration:  86% 636/743 [01:49<00:13,  7.83it/s]\u001b[A\n",
            "Iteration:  86% 637/743 [01:49<00:13,  7.80it/s]\u001b[A\n",
            "Iteration:  86% 638/743 [01:49<00:13,  7.77it/s]\u001b[A\n",
            "Iteration:  86% 639/743 [01:49<00:13,  7.80it/s]\u001b[A\n",
            "Iteration:  86% 640/743 [01:49<00:13,  7.78it/s]\u001b[A\n",
            "Iteration:  86% 641/743 [01:49<00:13,  7.79it/s]\u001b[A\n",
            "Iteration:  86% 642/743 [01:50<00:12,  7.80it/s]\u001b[A\n",
            "Iteration:  87% 643/743 [01:50<00:12,  7.79it/s]\u001b[A\n",
            "Iteration:  87% 644/743 [01:50<00:12,  7.76it/s]\u001b[A\n",
            "Iteration:  87% 645/743 [01:50<00:12,  7.79it/s]\u001b[A\n",
            "Iteration:  87% 646/743 [01:50<00:12,  7.80it/s]\u001b[A\n",
            "Iteration:  87% 647/743 [01:50<00:12,  7.79it/s]\u001b[A\n",
            "Iteration:  87% 648/743 [01:50<00:12,  7.81it/s]\u001b[A\n",
            "Iteration:  87% 649/743 [01:50<00:12,  7.82it/s]\u001b[A\n",
            "Iteration:  87% 650/743 [01:51<00:11,  7.84it/s]\u001b[A\n",
            "Iteration:  88% 651/743 [01:51<00:11,  7.83it/s]\u001b[A\n",
            "Iteration:  88% 652/743 [01:51<00:11,  7.84it/s]\u001b[A\n",
            "Iteration:  88% 653/743 [01:51<00:11,  7.83it/s]\u001b[A\n",
            "Iteration:  88% 654/743 [01:51<00:11,  7.82it/s]\u001b[A\n",
            "Iteration:  88% 655/743 [01:51<00:11,  7.81it/s]\u001b[A\n",
            "Iteration:  88% 656/743 [01:51<00:11,  7.83it/s]\u001b[A\n",
            "Iteration:  88% 657/743 [01:51<00:10,  7.83it/s]\u001b[A\n",
            "Iteration:  89% 658/743 [01:52<00:10,  7.83it/s]\u001b[A\n",
            "Iteration:  89% 659/743 [01:52<00:10,  7.82it/s]\u001b[A\n",
            "Iteration:  89% 660/743 [01:52<00:10,  7.82it/s]\u001b[A\n",
            "Iteration:  89% 661/743 [01:52<00:10,  7.82it/s]\u001b[A\n",
            "Iteration:  89% 662/743 [01:52<00:10,  7.83it/s]\u001b[A\n",
            "Iteration:  89% 663/743 [01:52<00:10,  7.83it/s]\u001b[A\n",
            "Iteration:  89% 664/743 [01:52<00:10,  7.83it/s]\u001b[A\n",
            "Iteration:  90% 665/743 [01:52<00:09,  7.84it/s]\u001b[A\n",
            "Iteration:  90% 666/743 [01:53<00:09,  7.83it/s]\u001b[A\n",
            "Iteration:  90% 667/743 [01:53<00:09,  7.79it/s]\u001b[A\n",
            "Iteration:  90% 668/743 [01:53<00:09,  7.78it/s]\u001b[A\n",
            "Iteration:  90% 669/743 [01:53<00:09,  7.80it/s]\u001b[A\n",
            "Iteration:  90% 670/743 [01:53<00:09,  7.82it/s]\u001b[A\n",
            "Iteration:  90% 671/743 [01:53<00:09,  7.83it/s]\u001b[A\n",
            "Iteration:  90% 672/743 [01:53<00:09,  7.83it/s]\u001b[A\n",
            "Iteration:  91% 673/743 [01:53<00:08,  7.83it/s]\u001b[A\n",
            "Iteration:  91% 674/743 [01:54<00:08,  7.83it/s]\u001b[A\n",
            "Iteration:  91% 675/743 [01:54<00:08,  7.81it/s]\u001b[A\n",
            "Iteration:  91% 676/743 [01:54<00:08,  7.79it/s]\u001b[A\n",
            "Iteration:  91% 677/743 [01:54<00:08,  7.80it/s]\u001b[A\n",
            "Iteration:  91% 678/743 [01:54<00:08,  7.81it/s]\u001b[A\n",
            "Iteration:  91% 679/743 [01:54<00:08,  7.82it/s]\u001b[A\n",
            "Iteration:  92% 680/743 [01:54<00:08,  7.82it/s]\u001b[A\n",
            "Iteration:  92% 681/743 [01:54<00:07,  7.82it/s]\u001b[A\n",
            "Iteration:  92% 682/743 [01:55<00:07,  7.82it/s]\u001b[A\n",
            "Iteration:  92% 683/743 [01:55<00:07,  7.81it/s]\u001b[A\n",
            "Iteration:  92% 684/743 [01:55<00:07,  7.81it/s]\u001b[A\n",
            "Iteration:  92% 685/743 [01:55<00:07,  7.81it/s]\u001b[A\n",
            "Iteration:  92% 686/743 [01:55<00:07,  7.78it/s]\u001b[A\n",
            "Iteration:  92% 687/743 [01:55<00:07,  7.79it/s]\u001b[A\n",
            "Iteration:  93% 688/743 [01:55<00:07,  7.80it/s]\u001b[A\n",
            "Iteration:  93% 689/743 [01:56<00:06,  7.81it/s]\u001b[A\n",
            "Iteration:  93% 690/743 [01:56<00:06,  7.81it/s]\u001b[A\n",
            "Iteration:  93% 691/743 [01:56<00:06,  7.79it/s]\u001b[A\n",
            "Iteration:  93% 692/743 [01:56<00:06,  7.75it/s]\u001b[A\n",
            "Iteration:  93% 693/743 [01:56<00:06,  7.77it/s]\u001b[A\n",
            "Iteration:  93% 694/743 [01:56<00:06,  7.77it/s]\u001b[A\n",
            "Iteration:  94% 695/743 [01:56<00:06,  7.77it/s]\u001b[A\n",
            "Iteration:  94% 696/743 [01:56<00:06,  7.76it/s]\u001b[A\n",
            "Iteration:  94% 697/743 [01:57<00:05,  7.77it/s]\u001b[A\n",
            "Iteration:  94% 698/743 [01:57<00:05,  7.66it/s]\u001b[A\n",
            "Iteration:  94% 699/743 [01:57<00:05,  7.70it/s]\u001b[A\n",
            "Iteration:  94% 700/743 [01:57<00:05,  7.73it/s]\u001b[A\n",
            "Iteration:  94% 701/743 [01:57<00:05,  7.76it/s]\u001b[A\n",
            "Iteration:  94% 702/743 [01:57<00:05,  7.78it/s]\u001b[A\n",
            "Iteration:  95% 703/743 [01:57<00:05,  7.78it/s]\u001b[A\n",
            "Iteration:  95% 704/743 [01:57<00:05,  7.79it/s]\u001b[A\n",
            "Iteration:  95% 705/743 [01:58<00:04,  7.79it/s]\u001b[A\n",
            "Iteration:  95% 706/743 [01:58<00:04,  7.78it/s]\u001b[A\n",
            "Iteration:  95% 707/743 [01:58<00:04,  7.78it/s]\u001b[A\n",
            "Iteration:  95% 708/743 [01:58<00:04,  7.78it/s]\u001b[A\n",
            "Iteration:  95% 709/743 [01:58<00:04,  7.78it/s]\u001b[A\n",
            "Iteration:  96% 710/743 [01:58<00:04,  7.78it/s]\u001b[A\n",
            "Iteration:  96% 711/743 [01:58<00:04,  7.79it/s]\u001b[A\n",
            "Iteration:  96% 712/743 [01:58<00:03,  7.80it/s]\u001b[A\n",
            "Iteration:  96% 713/743 [01:59<00:03,  7.80it/s]\u001b[A\n",
            "Iteration:  96% 714/743 [01:59<00:03,  7.80it/s]\u001b[A\n",
            "Iteration:  96% 715/743 [01:59<00:03,  7.80it/s]\u001b[A\n",
            "Iteration:  96% 716/743 [01:59<00:03,  7.79it/s]\u001b[A\n",
            "Iteration:  97% 717/743 [01:59<00:03,  7.78it/s]\u001b[A\n",
            "Iteration:  97% 718/743 [01:59<00:03,  7.74it/s]\u001b[A\n",
            "Iteration:  97% 719/743 [01:59<00:03,  7.76it/s]\u001b[A\n",
            "Iteration:  97% 720/743 [02:00<00:02,  7.76it/s]\u001b[A\n",
            "Iteration:  97% 721/743 [02:00<00:02,  7.77it/s]\u001b[A\n",
            "Iteration:  97% 722/743 [02:00<00:02,  7.77it/s]\u001b[A\n",
            "Iteration:  97% 723/743 [02:00<00:02,  7.78it/s]\u001b[A\n",
            "Iteration:  97% 724/743 [02:00<00:02,  7.79it/s]\u001b[A\n",
            "Iteration:  98% 725/743 [02:00<00:02,  7.63it/s]\u001b[A\n",
            "Iteration:  98% 726/743 [02:00<00:02,  7.52it/s]\u001b[A\n",
            "Iteration:  98% 727/743 [02:00<00:02,  7.41it/s]\u001b[A\n",
            "Iteration:  98% 728/743 [02:01<00:02,  7.44it/s]\u001b[A\n",
            "Iteration:  98% 729/743 [02:01<00:01,  7.52it/s]\u001b[A\n",
            "Iteration:  98% 730/743 [02:01<00:01,  7.55it/s]\u001b[A\n",
            "Iteration:  98% 731/743 [02:01<00:01,  7.62it/s]\u001b[A\n",
            "Iteration:  99% 732/743 [02:01<00:01,  7.68it/s]\u001b[A\n",
            "Iteration:  99% 733/743 [02:01<00:01,  7.70it/s]\u001b[A\n",
            "Iteration:  99% 734/743 [02:01<00:01,  7.73it/s]\u001b[A\n",
            "Iteration:  99% 735/743 [02:01<00:01,  7.75it/s]\u001b[A\n",
            "Iteration:  99% 736/743 [02:02<00:00,  7.77it/s]\u001b[A\n",
            "Iteration:  99% 737/743 [02:02<00:00,  7.75it/s]\u001b[A\n",
            "Iteration:  99% 738/743 [02:02<00:00,  7.63it/s]\u001b[A\n",
            "Iteration:  99% 739/743 [02:02<00:00,  7.69it/s]\u001b[A\n",
            "Iteration: 100% 740/743 [02:02<00:00,  7.74it/s]\u001b[A\n",
            "Iteration: 100% 741/743 [02:02<00:00,  7.78it/s]\u001b[A\n",
            "Iteration: 100% 742/743 [02:02<00:00,  7.80it/s]\u001b[A\n",
            "Iteration: 100% 743/743 [02:03<00:00,  6.04it/s]\n",
            "Epoch: 100% 1/1 [02:03<00:00, 123.00s/it]\n",
            "05/20/2024 18:49:53 - INFO - __main__ -    global_step = 743, average loss = 1.9926034932502346\n",
            "05/20/2024 18:49:53 - INFO - __main__ -   Saving model checkpoint to model_write_path\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1699: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n",
            "05/20/2024 18:50:04 - INFO - __main__ -   Evaluate the following checkpoints: ['model_write_path']\n",
            "05/20/2024 18:50:06 - INFO - __main__ -   Creating features from dataset file at /content\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (27878 > 2048). Running this sequence through the model will result in indexing errors\n",
            "05/20/2024 18:50:06 - INFO - __main__ -   Saving features into cached file /content/gpt2_cached_lm_150_test_.txt\n",
            "05/20/2024 18:50:06 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "05/20/2024 18:50:06 - INFO - __main__ -     Num examples = 185\n",
            "05/20/2024 18:50:06 - INFO - __main__ -     Batch size = 4\n",
            "Evaluating: 100% 47/47 [00:03<00:00, 14.36it/s]\n",
            "05/20/2024 18:50:09 - INFO - __main__ -   ***** Eval results  *****\n",
            "05/20/2024 18:50:09 - INFO - __main__ -     perplexity = tensor(6.5346)\n"
          ]
        }
      ],
      "source": [
        "!python {pretrain_path} \\\n",
        "    --output_dir=model_write_path \\\n",
        "    --model_type={model_type} \\\n",
        "    --model_name_or_path={model_load_path}  \\\n",
        "    --do_train \\\n",
        "    --train_data_file={train_path} \\\n",
        "    --do_eval \\\n",
        "    --eval_data_file={val_path} \\\n",
        "    --per_gpu_train_batch_size {per_gpu_batch_size} \\\n",
        "    --gradient_accumulation_steps {gradient_steps} \\\n",
        "    --num_train_epochs {num_train_epochs} \\\n",
        "    --block_size {block_size} \\\n",
        "    --overwrite_output_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Генерация и оценка точности модели**"
      ],
      "metadata": {
        "id": "Wr2s-gPpCpbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объявим более явно переменные для генерации и оценки точности модели и загрузим модель из директории `model_path`"
      ],
      "metadata": {
        "id": "BLKdUjT0Cyez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KreaODIPznGo"
      },
      "outputs": [],
      "source": [
        "model_path          = path['model_load']\n",
        "test_title_path     = path['test_promt']\n",
        "test_text           = path['test_text']\n",
        "path_save           = path['model_write']\n",
        "\n",
        "generator = GreetingsGenerator(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка модели"
      ],
      "metadata": {
        "id": "dw6sPXaKEPZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Перплексия** - это метрика, часто используемая для оценки языковых моделей. Она рассчитывается как экспонента средней потери на тестовом наборе.\n",
        "* **Косинусное сходство** можно использовать для оценки сходства между предложениями."
      ],
      "metadata": {
        "id": "PsW-RZluI9Rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, file_path, block_size=512):\n",
        "        assert os.path.isfile(file_path)\n",
        "        with open(file_path, encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        self.examples = []\n",
        "        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
        "\n",
        "        for i in range(0, len(tokenized_text) - block_size + 1, block_size):\n",
        "            self.examples.append(\n",
        "                tokenizer.build_inputs_with_special_tokens(tokenized_text[i : i + block_size])\n",
        "            )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return torch.tensor(self.examples[i], dtype=torch.long)\n",
        "\n",
        "def load_dataset(tokenizer, file_path, block_size=512):\n",
        "    return TextDataset(tokenizer, file_path, block_size)"
      ],
      "metadata": {
        "id": "z2_JW6VfER1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------ вычисление перплексии ------\n",
        "import math\n",
        "\n",
        "def evaluate_perplexity(model, eval_dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in eval_dataloader:\n",
        "        inputs, labels = (batch, batch)\n",
        "        inputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        labels = labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    avg_loss = total_loss / nb_eval_steps\n",
        "    perplexity = math.exp(avg_loss)\n",
        "    return perplexity\n",
        "\n",
        "# Загрузка модели и данных\n",
        "model_path = \"model_write_path/checkpoint-last\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "test_dataset = load_dataset(tokenizer, 'path_to_test_data.txt', block_size=512)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
        "\n",
        "# Вычисление перплексии\n",
        "perplexity = evaluate_perplexity(model, test_dataloader)\n",
        "print(f\"Perplexity: {perplexity}\")"
      ],
      "metadata": {
        "id": "IukaIB_wI1nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------ вычисление косинусного сходства ------\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def encode_texts(tokenizer, texts, model):\n",
        "    encodings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "        inputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        encodings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
        "    return np.vstack(encodings)\n",
        "\n",
        "def evaluate_cosine_similarity(model, tokenizer, reference_texts, generated_texts):\n",
        "    reference_encodings = encode_texts(tokenizer, reference_texts, model)\n",
        "    generated_encodings = encode_texts(tokenizer, generated_texts, model)\n",
        "    similarities = cosine_similarity(reference_encodings, generated_encodings)\n",
        "    avg_similarity = np.mean(np.diag(similarities))\n",
        "    return avg_similarity\n",
        "\n",
        "# Пример использования:\n",
        "reference_texts = [\"Это пример эталонного текста.\"]  # замените на ваши эталонные тексты\n",
        "generated_texts = [\"Это пример сгенерированного текста.\"]  # замените на ваши сгенерированные тексты\n",
        "\n",
        "cosine_similarity_score = evaluate_cosine_similarity(model, tokenizer, reference_texts, generated_texts)\n",
        "print(f\"Cosine Similarity: {cosine_similarity_score}\")"
      ],
      "metadata": {
        "id": "X_kFlHzrI3Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Примеры"
      ],
      "metadata": {
        "id": "Dnv-48_ZELqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В переменной `promt` находится промт для генерации.\n",
        "\n",
        "Пример №1"
      ],
      "metadata": {
        "id": "sFq20QA-DGuT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmVGzjwdbISn"
      },
      "outputs": [],
      "source": [
        "promt = '<s>Ключевые слова: [Праздник: На день рождения][Для кого: Подруге][Описание: Красивые] ->\\nПоздравление:'\n",
        "\n",
        "generation = generator.generate(promt)\n",
        "\n",
        "print(generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример №2"
      ],
      "metadata": {
        "id": "YX1TgyA-Ds73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGm_af1zk7ou"
      },
      "outputs": [],
      "source": [
        "generation = generator.generate(\"\"\"[holiday: На день рождения][to: Мужчине][description: С днем рождения стильное]->\\nПоздравление:\"\"\")\n",
        "print(generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример №3"
      ],
      "metadata": {
        "id": "TL74I6s0DvZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZKwj2g71BNL"
      },
      "outputs": [],
      "source": [
        "generation = generator.generate(\"\"\"Поздравление для бабушки с днем рождения:\n",
        "Бабушка, желаю \"\"\")\n",
        "print(generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример №4"
      ],
      "metadata": {
        "id": "Fgzcovg2D3p9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6goqri6ziKP"
      },
      "outputs": [],
      "source": [
        "generation = generator.generate(\"\"\"Поздравление для мамы с днем рождения:\n",
        "Мамочка, поздравляю тебя \"\"\")\n",
        "print(generation)"
      ]
    }
  ]
}